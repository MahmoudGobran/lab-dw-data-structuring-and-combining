{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {
    "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e"
   },
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {
    "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986"
   },
   "source": [
    "## Challenge 1: Combining & Cleaning Data\n",
    "\n",
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the links below.\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Note that you'll need to clean and format the new data.\n",
    "\n",
    "Observation:\n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {
    "id": "492d06e3-92c7-4105-ac72-536db98d3244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Summary:\n",
      "File1: 4008 rows, 11 columns\n",
      "File2: 996 rows, 11 columns\n",
      "File3: 7070 rows, 11 columns\n",
      "\n",
      "Original Column Names:\n",
      "File1 Columns: ['Customer', 'ST', 'GENDER', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class', 'Total Claim Amount']\n",
      "File2 Columns: ['Customer', 'ST', 'GENDER', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Total Claim Amount', 'Policy Type', 'Vehicle Class']\n",
      "File3 Columns: ['Customer', 'State', 'Customer Lifetime Value', 'Education', 'Gender', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Total Claim Amount', 'Vehicle Class']\n",
      "\n",
      "Differences Between Columns:\n",
      "File1 vs File2: []\n",
      "File1 vs File3: ['GENDER', 'Gender', 'ST', 'State']\n",
      "File2 vs File3: ['GENDER', 'Gender', 'ST', 'State']\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the files\n",
    "file1 = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\")\n",
    "file2 = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\")\n",
    "file3 = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\")\n",
    "\n",
    "# Show rows and columns\n",
    "print(\"Shape Summary:\")\n",
    "print(f\"File1: {file1.shape[0]} rows, {file1.shape[1]} columns\")\n",
    "print(f\"File2: {file2.shape[0]} rows, {file2.shape[1]} columns\")\n",
    "print(f\"File3: {file3.shape[0]} rows, {file3.shape[1]} columns\")\n",
    "\n",
    "# Print original column names\n",
    "print(\"\\nOriginal Column Names:\")\n",
    "print(\"File1 Columns:\", list(file1.columns))\n",
    "print(\"File2 Columns:\", list(file2.columns))\n",
    "print(\"File3 Columns:\", list(file3.columns))\n",
    "\n",
    "# Convert to sets to compare differences\n",
    "cols1 = set(file1.columns)\n",
    "cols2 = set(file2.columns)\n",
    "cols3 = set(file3.columns)\n",
    "\n",
    "print(\"\\nDifferences Between Columns:\")\n",
    "print(\"File1 vs File2:\", sorted(cols1.symmetric_difference(cols2)))\n",
    "print(\"File1 vs File3:\", sorted(cols1.symmetric_difference(cols3)))\n",
    "print(\"File2 vs File3:\", sorted(cols2.symmetric_difference(cols3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d3747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned File1 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n",
      "\n",
      "Cleaned File2 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'total_claim_amount', 'policy_type', 'vehicle_class']\n",
      "\n",
      "Cleaned File3 Columns:\n",
      "['customer', 'state', 'customer_lifetime_value', 'education', 'gender', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'total_claim_amount', 'vehicle_class']\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "    return df\n",
    "\n",
    "file1 = clean_columns(file1)\n",
    "file2 = clean_columns(file2)\n",
    "file3 = clean_columns(file3)\n",
    "\n",
    "# Print cleaned column names to confirm fix\n",
    "print(\"\\nCleaned File1 Columns:\")\n",
    "print(file1.columns.tolist())\n",
    "print(\"\\nCleaned File2 Columns:\")\n",
    "print(file2.columns.tolist())\n",
    "print(\"\\nCleaned File3 Columns:\")\n",
    "print(file3.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9fa911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in File1: 2936 rows\n",
      "Duplicates in File2: 0 rows\n",
      "Duplicates in File3: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in each file\n",
    "duplicates_file1 = file1.duplicated().sum()\n",
    "duplicates_file2 = file2.duplicated().sum()\n",
    "duplicates_file3 = file3.duplicated().sum()\n",
    "\n",
    "# Print the number of duplicate rows\n",
    "print(f\"Duplicates in File1: {duplicates_file1} rows\")\n",
    "print(f\"Duplicates in File2: {duplicates_file2} rows\")\n",
    "print(f\"Duplicates in File3: {duplicates_file3} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc31d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows in File1:\n",
      "     customer   st gender education customer_lifetime_value  income  \\\n",
      "1072      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "1073      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "1074      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "1075      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "1076      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "...       ...  ...    ...       ...                     ...     ...   \n",
      "4003      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "4004      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "4005      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "4006      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "4007      NaN  NaN    NaN       NaN                     NaN     NaN   \n",
      "\n",
      "      monthly_premium_auto number_of_open_complaints policy_type  \\\n",
      "1072                   NaN                       NaN         NaN   \n",
      "1073                   NaN                       NaN         NaN   \n",
      "1074                   NaN                       NaN         NaN   \n",
      "1075                   NaN                       NaN         NaN   \n",
      "1076                   NaN                       NaN         NaN   \n",
      "...                    ...                       ...         ...   \n",
      "4003                   NaN                       NaN         NaN   \n",
      "4004                   NaN                       NaN         NaN   \n",
      "4005                   NaN                       NaN         NaN   \n",
      "4006                   NaN                       NaN         NaN   \n",
      "4007                   NaN                       NaN         NaN   \n",
      "\n",
      "     vehicle_class  total_claim_amount  \n",
      "1072           NaN                 NaN  \n",
      "1073           NaN                 NaN  \n",
      "1074           NaN                 NaN  \n",
      "1075           NaN                 NaN  \n",
      "1076           NaN                 NaN  \n",
      "...            ...                 ...  \n",
      "4003           NaN                 NaN  \n",
      "4004           NaN                 NaN  \n",
      "4005           NaN                 NaN  \n",
      "4006           NaN                 NaN  \n",
      "4007           NaN                 NaN  \n",
      "\n",
      "[2936 rows x 11 columns]\n",
      "\n",
      "Duplicate rows in File2:\n",
      "Empty DataFrame\n",
      "Columns: [customer, st, gender, education, customer_lifetime_value, income, monthly_premium_auto, number_of_open_complaints, total_claim_amount, policy_type, vehicle_class]\n",
      "Index: []\n",
      "\n",
      "Duplicate rows in File3:\n",
      "Empty DataFrame\n",
      "Columns: [customer, state, customer_lifetime_value, education, gender, income, monthly_premium_auto, number_of_open_complaints, policy_type, total_claim_amount, vehicle_class]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# View duplicates in each file \n",
    "print(\"\\nDuplicate rows in File1:\")\n",
    "print(file1[file1.duplicated()])\n",
    "\n",
    "print(\"\\nDuplicate rows in File2:\")\n",
    "print(file2[file2.duplicated()])\n",
    "\n",
    "print(\"\\nDuplicate rows in File3:\")\n",
    "print(file3[file3.duplicated()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5265a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File1 after removing duplicates: 1072 rows, 11 columns\n",
      "File2 after removing duplicates: 996 rows, 11 columns\n",
      "File3 after removing duplicates: 7070 rows, 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from each dataset\n",
    "file1 = file1.drop_duplicates()\n",
    "file2 = file2.drop_duplicates()\n",
    "file3 = file3.drop_duplicates()\n",
    "\n",
    "# Check if there were any duplicates removed\n",
    "print(f\"File1 after removing duplicates: {file1.shape[0]} rows, {file1.shape[1]} columns\")\n",
    "print(f\"File2 after removing duplicates: {file2.shape[0]} rows, {file2.shape[1]} columns\")\n",
    "print(f\"File3 after removing duplicates: {file3.shape[0]} rows, {file3.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8095299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned File1 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n",
      "\n",
      "Cleaned File2 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n",
      "\n",
      "Cleaned File3 Columns:\n",
      "['customer', 'state', 'customer_lifetime_value', 'education', 'gender', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'total_claim_amount', 'vehicle_class']\n"
     ]
    }
   ],
   "source": [
    "# Ensure all datasets have the same column order (using the columns from the first file)\n",
    "#file2 = file2[file1.columns]\n",
    "#file3 = file3[file1.columns]\n",
    "\n",
    "# Print column names for the three files to confirm same order\n",
    "print(\"\\nCleaned File1 Columns:\")\n",
    "print(file1.columns.tolist())\n",
    "print(\"\\nCleaned File2 Columns:\")\n",
    "print(file2.columns.tolist())\n",
    "print(\"\\nCleaned File3 Columns:\")\n",
    "print(file3.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed01936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned File1 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n",
      "\n",
      "Cleaned File2 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n",
      "\n",
      "Cleaned File3 Columns:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n"
     ]
    }
   ],
   "source": [
    "# Rename 'state' to 'st' in file3\n",
    "file3.rename(columns={'state': 'st'}, inplace=True)\n",
    "\n",
    "#Ensure all datasets have the same column order (using the columns from file1)\n",
    "file2 = file2[file1.columns]\n",
    "file3 = file3[file1.columns]\n",
    "\n",
    "# Print column names for the three files to confirm same order\n",
    "print(\"\\nCleaned File1 Columns:\")\n",
    "print(file1.columns.tolist())\n",
    "print(\"\\nCleaned File2 Columns:\")\n",
    "print(file2.columns.tolist())\n",
    "print(\"\\nCleaned File3 Columns:\")\n",
    "print(file3.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c6ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Shape: 9138 rows, 11 columns\n",
      "\n",
      "Columns in Combined Data:\n",
      "['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']\n"
     ]
    }
   ],
   "source": [
    "# Combine the datasets\n",
    "combined_data = pd.concat([file1, file2, file3], ignore_index=True)\n",
    "\n",
    "# Check the shape and columns of the combined dataset\n",
    "print(f\"Combined Data Shape: {combined_data.shape[0]} rows, {combined_data.shape[1]} columns\")\n",
    "print(\"\\nColumns in Combined Data:\")\n",
    "print(combined_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {
    "id": "31b8a9e7-7db9-4604-991b-ef6771603e57"
   },
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {
    "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {
    "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the dataset:\n",
      "['unnamed:_0', 'customer', 'state', 'customer_lifetime_value', 'response', 'coverage', 'education', 'effective_to_date', 'employmentstatus', 'gender', 'income', 'location_code', 'marital_status', 'monthly_premium_auto', 'months_since_last_claim', 'months_since_policy_inception', 'number_of_open_complaints', 'number_of_policies', 'policy_type', 'policy', 'renew_offer_type', 'sales_channel', 'total_claim_amount', 'vehicle_class', 'vehicle_size', 'vehicle_type', 'month']\n",
      "\n",
      "Total Revenue by Sales Channel:\n",
      "               total_claim_amount\n",
      "sales_channel                    \n",
      "Agent                  1810226.82\n",
      "Branch                 1301204.00\n",
      "Call Center             926600.82\n",
      "Web                     706600.04\n",
      "\n",
      "Average Customer Lifetime Value by Gender and Education Level:\n",
      "                             customer_lifetime_value\n",
      "gender education                                    \n",
      "F      Bachelor                              7874.27\n",
      "       College                               7748.82\n",
      "       Doctor                                7328.51\n",
      "       High School or Below                  8675.22\n",
      "       Master                                8157.05\n",
      "M      Bachelor                              7703.60\n",
      "       College                               8052.46\n",
      "       Doctor                                7415.33\n",
      "       High School or Below                  8149.69\n",
      "       Master                                8168.83\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided URL\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Clean the column names\n",
    "data.columns = data.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "\n",
    "# Check the columns in the dataset\n",
    "print(\"\\nColumns in the dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Pivot Table 1 - Total revenue by sales channel\n",
    "# assuming 'total_claim_amount' is the column for revenue and 'sales_channel' is the sales channel column\n",
    "pivot_revenue = data.pivot_table(\n",
    "    values='total_claim_amount',  # Column to calculate total revenue\n",
    "    index='sales_channel',        # Group by sales channel\n",
    "    aggfunc='sum'                 # Aggregate by sum (total revenue)\n",
    ").round(2)                       # Round to 2 decimal points\n",
    "\n",
    "# Display the total revenue by sales channel\n",
    "print(\"\\nTotal Revenue by Sales Channel:\")\n",
    "print(pivot_revenue)\n",
    "\n",
    "# Pivot Table 2 - Average customer lifetime value per gender and education level\n",
    "# assuming 'customer_lifetime_value' is the column for lifetime value\n",
    "pivot_lifetime_value = data.pivot_table(\n",
    "    values='customer_lifetime_value',  # Column to calculate average customer lifetime value\n",
    "    index=['gender', 'education'],     # Group by gender and education level\n",
    "    aggfunc='mean'                     # Aggregate by mean (average lifetime value)\n",
    ").round(2)                           # Round to 2 decimal points\n",
    "\n",
    "# Display the average customer lifetime value per gender and education level\n",
    "print(\"\\nAverage Customer Lifetime Value by Gender and Education Level:\")\n",
    "print(pivot_lifetime_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {
    "id": "df35fd0d-513e-4e77-867e-429da10a9cc7"
   },
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {
    "id": "640993b2-a291-436c-a34d-a551144f8196"
   },
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {
    "id": "32c7f2e5-3d90-43e5-be33-9781b6069198"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {
    "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291"
   },
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {
    "id": "3a069e0b-b400-470e-904d-d17582191be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Complaints by Policy Type and Month:\n",
      "      policy_type  month  number_of_open_complaints\n",
      "0  Corporate Auto      1                 443.434952\n",
      "1  Corporate Auto      2                 385.208135\n",
      "2   Personal Auto      1                1727.605722\n",
      "3   Personal Auto      2                1453.684441\n",
      "4    Special Auto      1                  87.074049\n",
      "5    Special Auto      2                  95.226817\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Summary table for the number of complaints by policy type and month\n",
    "# Assuming 'number_of_open_complaints' is the column for complaints and 'policy_type' and 'month' for grouping\n",
    "complaints_summary = data.pivot_table(\n",
    "    values='number_of_open_complaints',  # Column to count the number of complaints\n",
    "    index=['policy_type', 'month'],     # Group by policy type and month\n",
    "    aggfunc='sum'                       # Aggregate by sum (total number of complaints)\n",
    ").reset_index()                        # Reset index to make it a flat table\n",
    "\n",
    "# Display the summary table for complaints by policy type and month\n",
    "print(\"\\nNumber of Complaints by Policy Type and Month:\")\n",
    "print(complaints_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8311a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
